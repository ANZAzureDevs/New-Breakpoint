## 2022-11-22 - Series 2 - Episode 12: A GitOps approach to multi-microservice and environment apps with Azure Red Hat OpenShift - Q&A

During the live session we did a live Q&A spot where attendees could ask questions. If you didn't manage to make it along, here are the ones that came up. We've included answers where possible.

### ❔ Q1: If we have hundreds of micro services and only one triggered a change through a pull request (PR) does the ArgoCD pipeline take time to reach to the change that triggered the deployment??

Each microservice in the demonstrated solution has its own branch per environment. ArgoCD is told through applications via the central repo which branches\charts to monitor. Currently the demo uses the default sync option which allows ArgoCD to poll the Git API (you can throttle up or down this setting - default every 3 minutes) to see if there has been a change to the branch\chart. ArgoCD can poll thousands of branches\chart easily - it will be the Git provider that complains when it gets too much which Paul has seen before where he had to throttle back how often ArgoCD was polling the branches. 

There are other ways to sync however, one of which is using an ArgoCD binary in your pipeline to contact ArgoCD and forcibly tell it to sync once you have updated a branch or chart. This can be secured using a token generated in ArgoCD. There is also another product called ArgoCD rollouts which is like a bolt-on to ArgoCD - where you can generate a non-live canary deployment, run integrated tests against that non-live container then switch it live and remove the old deployment - this method is what the demo will eventually move to. So with ArgoCD rollouts - you update your branches and as each branch update will sync the non-live deployment using the binary, test it, once tests run true tell ArgoCD to make it live and then move on to the next one (skipping the forced sync of any branches that have not updated). 

### ❔ Q2: That was great session. The current market conditions seems security is a key item that we have to address... Mainly as we are using open source packages etc... what kind of security features or tools or measures that can be or recommended while implementing ArgoCD pipelines please?

Within ArgoCD there are many security features. ArgoCD supports RBAC, and when using Openshift SSO with ArgoCD, which comes out of the box, you can lock down which applications teams can see what ArgoCD applications and how they can interact with them. One of OpenShift's great features is that it supports true multi-tenancy and you can sync Azure AD users and groups to the RBAC in the OpenShift Kubernetes cluster which gives you the power to tie teams\groups to Kubernetes application namespaces and in turn they can then be applied to ArgoCD projects to lock them down too. Hence you have AD groups set up on the Kubernetes clusters and users will have access to only their Kubernetes namespaces and only their ArgoCD projects\applications, authenticated via Azure AD. 

Additionally within ArgoCD projects you can restrict what resources can be deployed. For example: deny deployment of CRDs for this application team to the cluster, what namespaces can be deployed to and what repos can be accessed. There are also global settings for resource restrictions across all projects\applications with many blocked by default. Finally there are a host of different authentication methods that ArgoCD supports to authenticate to Helm and Git. The demo uses a combination of SSH and Git tokens. There are also a variety of secure auth methods for users to the UI and tokens to interact with the ArgoCD API for syncing. ArgoCD fosters least privileges access - in the demo no one requires access to the Kubernetes cluster via pipelines and no one needs any admin type user privilege access in the OpenShift UI or ArgoCD UI. You can check out the [ArgoCD security overview](https://argo-cd.readthedocs.io/en/stable/operator-manual/security/) for more details.

### ❔ Q3: If Azure DevOps have been taking care of Infrastructure deployments (via Helm Upgrade) for our company for a while is ArgoCD worth moving our deployment manifests to or will Azure DevOps eventually have GitOps functionality?

If you are deploying Helm via Helm upgrade, I would definitely recommend moving to GitOps tooling to do polling-based or pull-based syncing of the manifest to the Kubernetes cluster such as ArgoCD. That doesn't mean you would get rid of Azure Devops as it is the equivalent of Tekton in the demo solution which I very much need to do all the Continuous Integration (CI) bits and pieces. As stated in question time of the presentation, doing a push-based approach like you are using requires giving pipeline Kubernetes cluster access which you don't need in the demonstrated solution. The other downside with your current method is it means your Kubernetes cluster is a collection of point-in-time pipeline deployments to the cluster as opposed to a Git-backed version-controlled cluster where your cluster reflects what's in Git right now and gives you the confidence that its deployed correctly. Azure Devops may never be a GitOps tool but it can interact with a GitOps tool like Tekton, building my charts and updating the branches that ArgoCD watches for changes on.